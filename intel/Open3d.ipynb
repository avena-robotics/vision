{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec988638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Open3D INFO] Resetting default logger to print to terminal.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import open3d as o3d\n",
    "from open3d.web_visualizer import draw\n",
    "import time\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aef52770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_camera(config_filename, number_of_images=1):\n",
    "    camera_rgbd_images = []\n",
    "\n",
    "    # Load JSON with configuration\n",
    "    with open(config_filename) as cf:\n",
    "        rs_cfg = o3d.t.io.RealSenseSensorConfig(json.load(cf))\n",
    "\n",
    "    # Initialize device and get metadata\n",
    "    rscam = o3d.t.io.RealSenseSensor()\n",
    "    rscam.init_sensor(rs_cfg)\n",
    "    rgbd_metadata = rscam.get_metadata()\n",
    "\n",
    "    # Get intrinsic parameters from metadata\n",
    "    fx = rgbd_metadata.intrinsics.intrinsic_matrix[0][0]\n",
    "    fy = rgbd_metadata.intrinsics.intrinsic_matrix[1][1]\n",
    "    ppx = rgbd_metadata.intrinsics.intrinsic_matrix[0][2]\n",
    "    ppy = rgbd_metadata.intrinsics.intrinsic_matrix[1][2]\n",
    "    height = rgbd_metadata.height\n",
    "    width = rgbd_metadata.width\n",
    "\n",
    "\n",
    "\n",
    "    # Start acquiring images\n",
    "    rscam.start_capture(start_record=True)\n",
    "    print('Waiting 2 seconds for camera to start...')\n",
    "    time.sleep(2)\n",
    "    print('Capturing frames')\n",
    "    #mask_depth = cv2.imread(\"/home/avena/PycharmProjects/tsdf_gpu/input/01_mask_c1_16u.png\", cv2.IMREAD_UNCHANGED)\n",
    "    #mask_color = cv2.imread(\"/home/avena/PycharmProjects/tsdf_gpu/input/01_mask_c1_8u.png\", cv2.IMREAD_UNCHANGED)\n",
    "    #mask_color = cv2.cvtColor(mask_color, cv2.COLOR_GRAY2RGB)\n",
    "    #mask_depth = mask_depth.astype(np.float32)\n",
    "    #print(mask_color.shape)\n",
    "    #print(mask_depth.shape)\n",
    "    for image_idx in range(number_of_images):\n",
    "        rgbd_frame = rscam.capture_frame(align_depth_to_color=True)\n",
    "        rgbd_frame = rgbd_frame.to_legacy_rgbd_image()\n",
    "        depth = np.asarray(rgbd_frame.depth).astype(np.float32)\n",
    "        color = np.asarray(rgbd_frame.color)\n",
    "        print(color.shape)\n",
    "        # Bilateral filter\n",
    "        # depth_filtered = cv2.bilateralFilter(src=depth,\n",
    "        #                                      d=3,\n",
    "        #                                      sigmaColor=2,\n",
    "        #                                      sigmaSpace=2,\n",
    "        #                                      borderType=cv2.BORDER_CONSTANT\n",
    "        #                                      )\n",
    "        #\n",
    "        #\n",
    "        # color = cv2.bitwise_and(color, mask_color)\n",
    "        # depth_filtered = cv2.bitwise_and(depth_filtered, mask_depth)\n",
    "\n",
    "        depth_filtered = cv2.ximgproc.jointBilateralFilter(joint=color.astype(np.float32),\n",
    "                                                           src=depth,\n",
    "                                                           d=3,\n",
    "                                                           sigmaColor=2,\n",
    "                                                           sigmaSpace=2,\n",
    "                                                           borderType=cv2.BORDER_CONSTANT).astype(np.uint16)\n",
    "        # depth_filtered = depth\n",
    "\n",
    "        color_tensor = o3d.core.Tensor(color, dtype=o3d.core.Dtype.UInt8)\n",
    "        depth_tensor = o3d.core.Tensor(depth_filtered, dtype=o3d.core.Dtype.UInt16)\n",
    "        color_image = o3d.t.geometry.Image(color_tensor)\n",
    "        depth_image = o3d.t.geometry.Image(depth_tensor)\n",
    "        rgbd_frame = o3d.t.geometry.RGBDImage(color_image, depth_image)\n",
    "\n",
    "        camera_rgbd_images.append(rgbd_frame)\n",
    "\n",
    "    # Stop device\n",
    "    rscam.stop_capture()\n",
    "\n",
    "    # Return results\n",
    "    return camera_rgbd_images, {\"fx\": fx, \"fy\": fy, \"cx\": ppx, \"cy\": ppy, \"height\": height, \"width\": width}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8377c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsdf_volume(frames, camera_info, device):\n",
    "    # TSDF volume initialization\n",
    "    volume = o3d.t.geometry.TSDFVoxelGrid(\n",
    "        map_attrs_to_dtypes={\n",
    "            'tsdf': o3d.core.Dtype.Float32,\n",
    "            'weight': o3d.core.Dtype.UInt16,\n",
    "            'color': o3d.core.Dtype.UInt16\n",
    "        },\n",
    "        voxel_size=0.002,\n",
    "        sdf_trunc=0.005,\n",
    "        block_resolution=16,\n",
    "        block_count=50000,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Same camera, so transform is identity\n",
    "    extrinsic = np.eye(4)\n",
    "    extrinsic_gpu = o3d.core.Tensor(extrinsic, o3d.core.Dtype.Float32, device)\n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic(width=camera_info[\"width\"],\n",
    "                                                  height=camera_info[\"height\"],\n",
    "                                                  fx=camera_info[\"fx\"], fy=camera_info[\"fy\"],\n",
    "                                                  cx=camera_info[\"cx\"], cy=camera_info[\"cy\"])\n",
    "    intrinsic_gpu = o3d.core.Tensor(intrinsic.intrinsic_matrix, o3d.core.Dtype.Float32, device)\n",
    "\n",
    "    # Process each frame\n",
    "    start = time.perf_counter()\n",
    "    for frame in frames:\n",
    "        color_gpu = frame.color.to(device)\n",
    "        depth_gpu = frame.depth.to(device)\n",
    "        volume.integrate(depth=depth_gpu,\n",
    "                         color=color_gpu,\n",
    "                         intrinsics=intrinsic_gpu,\n",
    "                         extrinsics=extrinsic_gpu,\n",
    "                         depth_scale=1000.0,\n",
    "                         depth_max=1.2,\n",
    "                         )\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print('Mean compute time:', (end - start) / len(frames) * 1000, ' [ms]')\n",
    "\n",
    "    # Extract point cloud from volume\n",
    "    return_value = volume.cpu().extract_surface_points()\n",
    "\n",
    "    # But not sure whether this works or not...\n",
    "    o3d.core.cuda.release_cache()\n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03540a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_pointcloud(camera_config_path, device, frames_no):\n",
    "    frames, camera_info = stream_camera(camera_config_path, frames_no)\n",
    "    filtered_cloud = tsdf_volume(frames, camera_info, device)\n",
    "    return filtered_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f87e67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing using GPU\n",
      "Waiting 2 seconds for camera to start...[Open3D INFO] Capture started with RealSense camera 135222250712\n",
      "\n",
      "Capturing frames\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "[Open3D INFO] Capture stopped.\n",
      "Mean compute time: 1.7849533999651612  [ms]\n",
      "\u001b[1;33m[Open3D WARNING] No estimated max point cloud size provided, using a 2-pass estimation. Surface extraction could be slow.\u001b[0;m\n",
      "[Open3D INFO] Window window_0 created.\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "[Open3D INFO] ICE servers: {\"stun:stun.l.google.com:19302\", \"turn:user:password@34.69.27.100:3478\", \"turn:user:password@34.69.27.100:3478?transport=tcp\"}\n",
      "[Open3D INFO] Set WEBRTC_STUN_SERVER environment variable add a customized WebRTC STUN server.\n",
      "[Open3D INFO] WebRTC Jupyter handshake mode enabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to establish dbus connection"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b4a0659cd7498f84e27377bfaab5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/getIceServers\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/call\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/getIceCandidate\n"
     ]
    }
   ],
   "source": [
    "frames_no = 10\n",
    "\n",
    "print('Processing using GPU')\n",
    "device = o3d.core.Device(\"CUDA:0\")\n",
    "pcd_gpu = get_filtered_pointcloud(camera_config_path=\"input/cam7_config.json\",\n",
    "                                  device=device,\n",
    "                                  frames_no=frames_no\n",
    "                                  )\n",
    "\n",
    "# print('Processing using CPU')\n",
    "# device = o3d.core.Device(\"CPU:0\")\n",
    "# pcd_cpu = get_filtered_pointcloud(camera_config_path=\"/home/avena/PycharmProjects/tsdf/input/cam5_config.json\",\n",
    "#                                   device=device,\n",
    "#                                   frames_no=frames_no\n",
    "#                                   )\n",
    "#\n",
    "# o3d.visualization.draw([pcd_gpu, pcd_cpu])\n",
    "draw([pcd_gpu])\n",
    "\n",
    "# o3d.io.write_point_cloud(\"output/depth_bilateral_filter_gpu.ply\", pcd_gpu.to_legacy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9e50df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilateral_filter(img, d, sigma_color, sigma_space):\n",
    "    return cv2.bilateralFilter(img, d, sigma_color, sigma_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33bd9874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_bilateral_filter(color, depth, d, sigmaColor, sigmaSpace, borderType):\n",
    "    return cv2.ximgproc.jointBilateralFilter(joint=color,\n",
    "                                            src=depth,\n",
    "                                            d=d,\n",
    "                                            sigmaColor=sigmaColor,\n",
    "                                            sigmaSpace=sigmaSpace,\n",
    "                                            borderType=borderType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c6ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guided_filter(color, depth, radius, eps):\n",
    "    return cv2.ximgproc.guidedFilter(guide=color,\n",
    "                                    src=depth,\n",
    "                                    radius=radius,\n",
    "                                    eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff4ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radius_outlier_removal(point_cloud, nb_neighbors, std_ratio):\n",
    "    point_cloud = point_cloud.to_legacy_pointcloud()\n",
    "    _, ind = point_cloud.remove_statistical_outlier(nb_neighbors, std_ratio)\n",
    "    point_cloud = point_cloud.select_by_index(ind)\n",
    "    point_cloud_gpu = o3d.t.geometry.PointCloud.from_legacy_pointcloud(point_cloud)\n",
    "    return point_cloud_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6752ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_outlier_removal(point_cloud, nb_points, radius):\n",
    "    point_cloud = point_cloud.to_legacy_pointcloud()\n",
    "    _, ind = point_cloud.remove_radius_outlier(nb_points, radius)\n",
    "    point_cloud = point_cloud.select_by_index(ind)\n",
    "    point_cloud_gpu = o3d.t.geometry.PointCloud.from_legacy_pointcloud(point_cloud)\n",
    "    return point_cloud_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "911a0cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEngine (64 bits) created at 0x7f00280064d0 (threading is enabled)\n",
      "EGL(1.5)\n",
      "OpenGL(4.1)\n",
      "[Open3D INFO] Window window_1 created.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa2647f10314cdb81408cf2e0a43740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_1')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/getIceServers\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/call\n",
      "[Open3D INFO] DataChannelObserver::OnStateChange label: ServerDataChannel, state: open, peerid: 0.5134082588113147\n",
      "[Open3D INFO] DataChannelObserver::OnStateChange label: ClientDataChannel, state: open, peerid: 0.5134082588113147\n",
      "[Open3D INFO] Sending init frames to window_0.\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n"
     ]
    }
   ],
   "source": [
    "draw(radius_outlier_removal(pcd_gpu, 20, 2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7ac2073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd = radius_outlier_removal(pcd_gpu, 20, 2.0)\n",
    "pcd = pcd.to_legacy_pointcloud()\n",
    "o3d.io.write_point_cloud(\"nazwa.ply\",pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5809f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Window window_2 created.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef3788bda97472f9c5c5c9a7913a8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_2')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/getIceServers\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/getIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/getIceCandidate\n",
      "[Open3D INFO] DataChannelObserver::OnStateChange label: ServerDataChannel, state: open, peerid: 0.01151207486524397\n",
      "[Open3D INFO] DataChannelObserver::OnStateChange label: ClientDataChannel, state: open, peerid: 0.01151207486524397\n",
      "[Open3D INFO] Sending init frames to window_1.\n",
      "[Open3D INFO] DataChannelObserver::OnStateChange label: ServerDataChannel, state: open, peerid: 0.1922382302312633\n",
      "[Open3D INFO] DataChannelObserver::OnStateChange label: ClientDataChannel, state: open, peerid: 0.1922382302312633\n",
      "[Open3D INFO] Sending init frames to window_2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[000:000][63062] (stun_port.cc:96): Binding request timed out from 10.3.15.x:58964 (enp4s0)\n",
      "[000:005][63062] (stun_port.cc:96): Binding request timed out from 10.3.15.x:36957 (enp4s0)\n",
      "[003:208][63062] (stun_port.cc:96): Binding request timed out from 10.3.15.x:59859 (enp4s0)\n"
     ]
    }
   ],
   "source": [
    "draw(statistical_outlier_removal(pcd_gpu, 16, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b4454d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function bitwise_and>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.bitwise_and"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
